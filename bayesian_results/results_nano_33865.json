{
    "out_dir": [
        "out",
        "out",
        "out",
        "out",
        "out",
        "out"
    ],
    "eval_interval": [
        250,
        250,
        250,
        250,
        250,
        250
    ],
    "log_interval": [
        200,
        200,
        200,
        200,
        200,
        200
    ],
    "eval_iters": [
        10,
        10,
        10,
        10,
        10,
        10
    ],
    "eval_only": [
        false,
        false,
        false,
        false,
        false,
        false
    ],
    "always_save_checkpoint": [
        true,
        true,
        true,
        true,
        true,
        true
    ],
    "init_from": [
        "scratch",
        "scratch",
        "scratch",
        "scratch",
        "scratch",
        "scratch"
    ],
    "wandb_project": [
        "owt",
        "owt",
        "owt",
        "owt",
        "owt",
        "owt"
    ],
    "wandb_run_name": [
        "'nano'",
        "'nano'",
        "'nano'",
        "'nano'",
        "'nano'",
        "'nano'"
    ],
    "wandb_log": [
        false,
        false,
        false,
        false,
        false,
        false
    ],
    "dataset": [
        "openwebtext",
        "openwebtext",
        "openwebtext",
        "openwebtext",
        "openwebtext",
        "openwebtext"
    ],
    "gradient_accumulation_steps": [
        1,
        1,
        1,
        1,
        1,
        1
    ],
    "batch_size": [
        68,
        55,
        81,
        77,
        78,
        67
    ],
    "block_size": [
        256,
        256,
        256,
        256,
        256,
        256
    ],
    "n_layer": [
        6,
        6,
        6,
        6,
        6,
        6
    ],
    "n_head": [
        6,
        6,
        6,
        6,
        6,
        6
    ],
    "n_embd": [
        384,
        384,
        384,
        384,
        384,
        384
    ],
    "dropout": [
        0.2,
        0.2,
        0.2,
        0.2,
        0.2,
        0.2
    ],
    "bias": [
        false,
        false,
        false,
        false,
        false,
        false
    ],
    "vocab_size": [
        50304,
        50304,
        50304,
        50304,
        50304,
        50304
    ],
    "vocab_size_reason": [
        "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)",
        "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)",
        "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)",
        "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)",
        "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)",
        "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)"
    ],
    "learning_rate": [
        0.0009874852931977256,
        0.00040207092502713825,
        0.0007639103624644772,
        4.731415428462429e-05,
        0.00043851013871363837,
        6.399599713378047e-05
    ],
    "max_iters": [
        10000,
        10000,
        10000,
        10000,
        10000,
        10000
    ],
    "weight_decay": [
        0.059327167678979116,
        0.0038669703848923692,
        0.03571914239640789,
        0.09552482008180153,
        0.019541177536086574,
        0.012897059424509614
    ],
    "beta1": [
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9
    ],
    "beta2": [
        0.99,
        0.99,
        0.99,
        0.99,
        0.99,
        0.99
    ],
    "grad_clip": [
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "decay_lr": [
        true,
        true,
        true,
        true,
        true,
        true
    ],
    "warmup_iters": [
        100,
        100,
        100,
        100,
        100,
        100
    ],
    "lr_decay_iters": [
        10000,
        10000,
        10000,
        10000,
        10000,
        10000
    ],
    "min_lr": [
        0.0001,
        0.0001,
        0.0001,
        0.0001,
        0.0001,
        0.0001
    ],
    "backend": [
        "nccl",
        "nccl",
        "nccl",
        "nccl",
        "nccl",
        "nccl"
    ],
    "ddp_rank": [
        -1,
        -1,
        -1,
        -1,
        -1,
        -1
    ],
    "seed_offset": [
        0,
        0,
        0,
        0,
        0,
        0
    ],
    "ddp_world_size": [
        1,
        1,
        1,
        1,
        1,
        1
    ],
    "ddp_local_rank": [
        -1,
        -1,
        -1,
        -1,
        -1,
        -1
    ],
    "device": [
        "cuda",
        "cuda",
        "cuda",
        "cuda",
        "cuda",
        "cuda"
    ],
    "dtype": [
        "bfloat16",
        "bfloat16",
        "bfloat16",
        "bfloat16",
        "bfloat16",
        "bfloat16"
    ],
    "compile": [
        true,
        true,
        true,
        true,
        true,
        true
    ],
    "seed": [
        "33865",
        "33865",
        "33865",
        "33865",
        "33865",
        "33865"
    ],
    "time": [
        1596.6322915554047,
        1333.9026358127594,
        1826.2912044525146,
        1776.5225493907928,
        1805.4414002895355,
        1557.6457734107971
    ],
    "best_val_loss": [
        3.8953652381896973,
        4.043095588684082,
        3.864542007446289,
        4.4048051834106445,
        3.959192991256714,
        4.388626575469971
    ],
    "iter_num": [
        10001,
        10001,
        10001,
        10001,
        10001,
        10001
    ]
}